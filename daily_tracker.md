## Course 1

| Date        | Videos Done           | On Track  | Comments |
| ------------- |:-------------:| -----:|-----------------|
| 02/09/18  | Week 1 Done | Yes | Will See Hinton's Interview after this course |
| 04/09/18  | Week 2 In Progress LR using NN is done | Yes | Revise Graphs and Derivatives (Log and Exponential Functions |
| 05/09/18  | Week 2 Assignment Done and Completed | Yes | np.reshape() is a problem, Function of optimizer is also to be discussed |
| 06/09/18  | Week 3 Started Till Activation Functions | Yes | Why we use non linear Activation Function is Done and Understood! Explore more about various Activation Functions|
| 10/09/18  | Week 3 Done | Yes | Revise Derivatives of all. Don't cram formulas derive formulas later on or in interviews|
| 11/09/18  | Week 3 Completed with Programming Exercise | Yes | np.squeeze(), also sigmoid function does not computes the final output, log loss and cross entropy loss difference|
| 12/09/18  | Week 4 Videos done with Assingment | Yes | Backprop equations is still a gray area, hopefully this assignment will clear it|
| 13/09/18  | Week 4 Assingments are done | Yes |  Had hard time visualizing backpropagation but finally got the course certificate and knowledge, moving on to next|

## Course 2

| Date        | Videos Done           | On Track  | Comments |
| ------------- |:-------------:| -----:|-----------------|
| 14/09/18  | Week 1 Done till Regularization | Yes |L1 Regularization, L2 Regularization and (np.dot, np.muliply and np.matmul difference |
| 18/09/18  | Week 1 Done Complete | Yes |L1 Regularization, L2 Regularization are still points that need more attention, Gradient Checking is theoretical, will try to dive in further |
| 19/09/18  | Week 2 Done Till GD with Momentum | Yes | Exponential Weighted Averages a beautiful Algo for averaging out and then use GD with momentum (which means exponential averaging out the gradients)|
